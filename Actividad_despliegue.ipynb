{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb61c492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: streamlit in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.50.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (6.2.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (2.3.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (2.3.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (6.32.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e09139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: streamlit-plotly-events in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.0.6)\n",
      "Requirement already satisfied: streamlit>=0.63 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit-plotly-events) (1.50.0)\n",
      "Requirement already satisfied: plotly>=4.14.3 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit-plotly-events) (6.3.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from plotly>=4.14.3->streamlit-plotly-events) (2.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from plotly>=4.14.3->streamlit-plotly-events) (25.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (6.2.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (2.3.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (2.3.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (6.32.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=0.63->streamlit-plotly-events) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-plotly-events) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-plotly-events) (4.25.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from click<9,>=7.0->streamlit>=0.63->streamlit-plotly-events) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-plotly-events) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-plotly-events) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-plotly-events) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-plotly-events) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-plotly-events) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-plotly-events) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-plotly-events) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-plotly-events) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-plotly-events) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-plotly-events) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-plotly-events) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-plotly-events) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-plotly-events) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-plotly-events) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ajasa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.63->streamlit-plotly-events) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit-plotly-events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c39682b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting despliegue.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile despliegue.py\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats\n",
    "\n",
    "# ===================== CUSTOMIZACIÓN DEL DASHBOARD =====================\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "charts_palette = [\"#4458A6\", \"#7B4BA3\", \"#2F3B66\", \"#9768D1\", \"#4A5176\"]\n",
    "\n",
    "px.defaults.template = \"plotly_dark\"\n",
    "px.defaults.color_discrete_sequence = charts_palette\n",
    "px.defaults.width = None\n",
    "px.defaults.height = None\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"font.family\": \"Times New Roman\",\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "})\n",
    "sns.set_palette(charts_palette)\n",
    "\n",
    "def style_plotly(fig: go.Figure) -> go.Figure:\n",
    "    fig.update_layout(\n",
    "        font=dict(family=\"Times New Roman\", size=16),\n",
    "        title_font=dict(family=\"Times New Roman\", size=22),\n",
    "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        margin=dict(l=10, r=10, t=40, b=10),\n",
    "    )\n",
    "    # Opcional: quitar borde de marcadores en barras/dispersiones para look más limpio\n",
    "    fig.update_traces(marker_line_width=0)\n",
    "    return fig\n",
    "\n",
    "palette = charts_palette\n",
    "palette2 = [\"#4458A6\", \"#2F3B66\", \"#8F2D56\"]\n",
    "\n",
    "# Helper para mostrar cualquier figura con el estilo unificado\n",
    "def show(fig: go.Figure):\n",
    "    fig = style_plotly(fig)\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "######################################################\n",
    "# Definimos la instancia\n",
    "@st.cache_resource\n",
    "######################################################\n",
    "# Creamos la función de carga de datos\n",
    "def load_data():\n",
    "    # Lectura del archivo csv\n",
    "    df = pd.read_csv(\"Listings_sin_atipicos.csv\")\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "#columns_to_drop = ['Unnamed: 0', 'Unnamed: 0.1', 'id', 'scrape_id', 'host_id']\n",
    "#df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# ================== HELPERS GLOBALES ==================\n",
    "def vc_df(series, name_col):\n",
    "    \"\"\"Devuelve tabla de frecuencias con nombre estándar\"\"\"\n",
    "    t = series.value_counts(dropna=False).reset_index()\n",
    "    t.columns = [name_col, 'count']\n",
    "    t[name_col] = t[name_col].astype(object).where(t[name_col].notna(), 'Unknown').astype(str)\n",
    "    return t\n",
    "\n",
    "def to_num_money(series):\n",
    "    \"\"\"Convierte precios tipo '$1,234' a float\"\"\"\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "def to_num_pct(series):\n",
    "    \"\"\"Convierte porcentajes tipo '95%' a float\"\"\"\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.str.replace('%', '', regex=False).str.replace(',', '.', regex=False)\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "palette = ['#8F2D56', '#218380', '#FBB13C', '#73D2DE']\n",
    "\n",
    "# ================== LIMPIEZAS / COLUMNAS AUX ==================\n",
    "for col in ['availability_365', 'review_scores_value', 'bathrooms', 'beds']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "if 'host_acceptance_rate' in df.columns:\n",
    "    df['host_acceptance_rate'] = to_num_pct(df['host_acceptance_rate'])\n",
    "\n",
    "if 'host_is_superhost' in df.columns:\n",
    "    df['_superhost'] = (\n",
    "        df['host_is_superhost'].astype(str).str.lower()\n",
    "        .map({'t': True, 'true': True, '1': True, 'f': False, 'false': False, '0': False})\n",
    "    )\n",
    "else:\n",
    "    df['_superhost'] = np.nan\n",
    "\n",
    "# ---- Rangos de precio ----\n",
    "if '_price_num' in df.columns and df['_price_num'].notna().sum() > 0:\n",
    "    try:\n",
    "        qbins = pd.qcut(df['_price_num'], q=5, duplicates='drop')\n",
    "    except Exception:\n",
    "        qbins = pd.cut(\n",
    "            df['_price_num'],\n",
    "            bins=np.linspace(df['_price_num'].min(), df['_price_num'].max(), 6),\n",
    "            include_lowest=True\n",
    "        )\n",
    "    df['_price_bin'] = qbins\n",
    "\n",
    "    def bin_label(iv):\n",
    "        if pd.isna(iv):\n",
    "            return 'Unknown'\n",
    "        L = int(np.floor(iv.left)) if np.isfinite(iv.left) else iv.left\n",
    "        R = int(np.ceil(iv.right)) if np.isfinite(iv.right) else iv.right\n",
    "        return f\"{L:,} – {R:,}\"\n",
    "    uniq_bins = sorted(df['_price_bin'].dropna().unique(), key=lambda x: x.left)\n",
    "    price_labels_map = {iv: bin_label(iv) for iv in uniq_bins}\n",
    "\n",
    "    df['_price_bin_str'] = df['_price_bin'].map(lambda iv: price_labels_map.get(iv, 'Unknown')).astype(str)\n",
    "else:\n",
    "    df['_price_bin_str'] = 'Unknown'\n",
    "\n",
    "# ---- Review scores a categorías tipo Likert ----\n",
    "if 'review_scores_value' in df.columns and df['review_scores_value'].notna().sum() > 0:\n",
    "    rmin = float(np.nanmin(df['review_scores_value']))\n",
    "    rmax = float(np.nanmax(df['review_scores_value']))\n",
    "    bins_r = np.linspace(max(3.8, rmin), min(5.1, max(rmax, 5.0)), 6)\n",
    "    labels_r = ['Malo (3.8–4.1)', 'Regular (4.1–4.3)', 'Bueno (4.4–4.6)',\n",
    "                'Muy Bueno (4.7–4.9)', 'Excelente (5)']\n",
    "    df['_rev_cat'] = pd.cut(df['review_scores_value'], bins=bins_r,\n",
    "                            labels=labels_r, include_lowest=True)\n",
    "else:\n",
    "    df['_rev_cat'] = np.nan\n",
    "\n",
    "# ---- Top-5 para filtros ----\n",
    "if 'property_type' in df.columns:\n",
    "    top5_prop = df['property_type'].value_counts().head(5).index.astype(str).tolist()\n",
    "else:\n",
    "    top5_prop = []\n",
    "\n",
    "if 'neighbourhood_cleansed' in df.columns:\n",
    "    top5_neigh = df['neighbourhood_cleansed'].value_counts().head(5).index.astype(str).tolist()\n",
    "else:\n",
    "    top5_neigh = []\n",
    "\n",
    "# ================== SIDEBAR: MENÚ + FILTROS (cerrado) + APLICAR A dff ==================\n",
    "st.sidebar.title(\"Airbnb Mexico City\")\n",
    "\n",
    "# Menú principal\n",
    "View = st.sidebar.selectbox(\n",
    "    \"Tipo de Análisis\",\n",
    "    [\"Extracción de Características\", \"Regresión Lineal\",\n",
    "     \"Regresión No Lineal\", \"Regresión Logística\"],\n",
    "    key=\"menu_tipo_analisis\"\n",
    ")\n",
    "\n",
    "# Submenú\n",
    "Variable_Cat = None\n",
    "if View == \"Extracción de Características\":\n",
    "    Variable_Cat = st.sidebar.selectbox(\n",
    "        \"Características\",\n",
    "        [\"Host info\", \"Property type\", \"Overall\"],\n",
    "        key=\"menu_caracteristicas\"\n",
    "    )\n",
    "\n",
    "# --- Asegura top-5 antes de usarlos ---\n",
    "if 'property_type' in df.columns:\n",
    "    top5_prop = df['property_type'].astype(str).value_counts().head(5).index.tolist()\n",
    "else:\n",
    "    top5_prop = []\n",
    "\n",
    "if 'neighbourhood_cleansed' in df.columns:\n",
    "    top5_neigh = df['neighbourhood_cleansed'].astype(str).value_counts().head(5).index.tolist()\n",
    "else:\n",
    "    top5_neigh = []\n",
    "\n",
    "# --- Panel de Filtros (CERRADO) ---\n",
    "with st.sidebar.expander(\"Filtros\", expanded=False):\n",
    "\n",
    "    # Superhost (multiselect)\n",
    "    sup_options = ['True', 'False']\n",
    "    sup_sel = st.multiselect(\n",
    "        \"Host es Superhost\",\n",
    "        sup_options,\n",
    "        default=sup_options,\n",
    "        key=\"filtro_superhost\"\n",
    "    )\n",
    "\n",
    "    # Precio (slider)\n",
    "    if '_price_num' in df.columns and df['_price_num'].notna().any():\n",
    "        min_price = int(np.floor(df['_price_num'].min()))\n",
    "        max_price = int(np.ceil(df['_price_num'].max()))\n",
    "        price_range = st.slider(\n",
    "            \"Rango de Precio (moneda original)\",\n",
    "            min_value=min_price,\n",
    "            max_value=max_price,\n",
    "            value=(min_price, max_price),\n",
    "            step=max(1, (max_price - min_price) // 100),\n",
    "            key=\"price_slider\"\n",
    "        )\n",
    "    else:\n",
    "        price_range = None\n",
    "        st.info(\"No hay precios numéricos disponibles para el slider.\")\n",
    "\n",
    "    # Property Type (checkbox + multiselect)\n",
    "    use_property_filter = st.checkbox(\"Filtrar por Property Type (Top-5)\", value=False, key=\"chk_property\")\n",
    "    if 'property_type' in df.columns:\n",
    "        pt_options = top5_prop if len(top5_prop) > 0 else sorted(\n",
    "            df['property_type'].astype(str).unique().tolist()\n",
    "        )\n",
    "    else:\n",
    "        pt_options = []\n",
    "    if use_property_filter:\n",
    "        pt_sel = st.multiselect(\n",
    "            \"Selecciona Property Type\",\n",
    "            pt_options,\n",
    "            default=pt_options,\n",
    "            key=\"filtro_property\"\n",
    "        )\n",
    "    else:\n",
    "        pt_sel = pt_options  # no filtra (toma todo)\n",
    "\n",
    "    # Neighbourhood (checkbox + multiselect)\n",
    "    use_neigh_filter = st.checkbox(\"Filtrar por Neighbourhood (Top-5)\", value=False, key=\"chk_neigh\")\n",
    "    if 'neighbourhood_cleansed' in df.columns:\n",
    "        nb_options = top5_neigh if len(top5_neigh) > 0 else sorted(\n",
    "            df['neighbourhood_cleansed'].astype(str).unique().tolist()\n",
    "        )\n",
    "    else:\n",
    "        nb_options = []\n",
    "    if use_neigh_filter:\n",
    "        nb_sel = st.multiselect(\n",
    "            \"Selecciona Neighbourhood\",\n",
    "            nb_options,\n",
    "            default=nb_options,\n",
    "            key=\"filtro_neighbourhood\"\n",
    "        )\n",
    "    else:\n",
    "        nb_sel = nb_options  # no filtra (toma todo)\n",
    "\n",
    "    # Review Scores (checkbox + multiselect)\n",
    "    use_review_filter = st.checkbox(\"Filtrar por Review Scores Value\", value=False, key=\"chk_review\")\n",
    "    rv_options_all = ['Malo (3.8–4.1)', 'Regular (4.1–4.3)',\n",
    "                      'Bueno (4.4–4.6)', 'Muy Bueno (4.7–4.9)', 'Excelente (5)']\n",
    "    rv_existing = sorted([x for x in rv_options_all if '_rev_cat' in df.columns and x in df['_rev_cat'].astype(str).unique()])\n",
    "    if use_review_filter:\n",
    "        rv_sel = st.multiselect(\n",
    "            \"Selecciona Review Scores\",\n",
    "            rv_existing or ['(sin datos)'],\n",
    "            default=rv_existing or [],\n",
    "            key=\"filtro_review\"\n",
    "        )\n",
    "    else:\n",
    "        rv_sel = rv_existing  # no filtra (toma todo)\n",
    "\n",
    "# ================== APLICAR FILTROS A COPIA ==================\n",
    "dff = df.copy()\n",
    "\n",
    "# Superhost\n",
    "if '_superhost' not in dff.columns and 'host_is_superhost' in dff.columns:\n",
    "    dff['_superhost'] = (\n",
    "        dff['host_is_superhost'].astype(str).str.lower()\n",
    "        .map({'t': True, 'true': True, '1': True, 'f': False, 'false': False, '0': False})\n",
    "    )\n",
    "if sup_sel and set(sup_sel) != set(['True', 'False']) and '_superhost' in dff.columns:\n",
    "    sel_bools = [s.lower() == 'true' for s in sup_sel]\n",
    "    dff = dff[dff['_superhost'].isin(sel_bools)]\n",
    "\n",
    "# Precio (slider)\n",
    "if price_range is not None and '_price_num' in dff.columns:\n",
    "    dff = dff[(dff['_price_num'] >= price_range[0]) & (dff['_price_num'] <= price_range[1])]\n",
    "\n",
    "# Property type (activo solo si hay opciones)\n",
    "if pt_options and 'property_type' in dff.columns:\n",
    "    dff = dff[dff['property_type'].astype(str).isin(pt_sel)]\n",
    "\n",
    "# Neighbourhood (activo solo si hay opciones)\n",
    "if nb_options and 'neighbourhood_cleansed' in dff.columns:\n",
    "    dff = dff[dff['neighbourhood_cleansed'].astype(str).isin(nb_sel)]\n",
    "\n",
    "# Review scores (activo solo si hay opciones)\n",
    "if rv_existing and '_rev_cat' in dff.columns:\n",
    "    dff = dff[dff['_rev_cat'].astype(str).isin(rv_sel)]\n",
    "\n",
    "# ======================\n",
    "# GRÁFICAS SOLO SI ES HOST INFO\n",
    "# ======================\n",
    "if Variable_Cat == \"Host info\":\n",
    "    st.subheader(\"Información del Anfitrión\")\n",
    "    # ====== Fila 1 ======\n",
    "    c1, c2 = st.columns(2)\n",
    "\n",
    "    # Host response time (Barra)\n",
    "    with c1:\n",
    "        st.subheader(\"Host Response Time\")\n",
    "        if 'host_response_time' in dff.columns:\n",
    "            tabla = dff['host_response_time'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                            .rename(columns={'index': 'host_response_time'})\n",
    "            filtro = tabla[tabla['count'] > 100]\n",
    "            fig = px.bar(\n",
    "                filtro.sort_values('count', ascending=False),\n",
    "                x='host_response_time', y='count',\n",
    "                title='Host Response Time',\n",
    "                text='count',\n",
    "                color_discrete_sequence=palette\n",
    "            )\n",
    "            fig.update_layout(xaxis_title=None, yaxis_title='Frecuencia')\n",
    "            fig.update_xaxes(tickangle=45)\n",
    "            show(fig)\n",
    "\n",
    "        else:\n",
    "            st.warning(\"No existe la columna 'host_response_time'.\")\n",
    "\n",
    "    # Host is superhost (Pie)\n",
    "    with c2:\n",
    "        st.subheader(\"Host is Superhost\")\n",
    "        if 'host_is_superhost' in dff.columns:\n",
    "            tabla = dff['host_is_superhost'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                            .rename(columns={'index': 'host_is_superhost'})\n",
    "            fig = px.pie(\n",
    "                tabla,\n",
    "                names='host_is_superhost', values='count',\n",
    "                title='Host is Superhost',\n",
    "                hole=0.25,\n",
    "                color_discrete_sequence=palette[:2]\n",
    "            )\n",
    "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            show(fig)\n",
    "        else:\n",
    "            st.warning(\"No existe la columna 'host_is_superhost'.\")\n",
    "\n",
    "    # ====== Fila 2 ======\n",
    "    c3, c4 = st.columns(2)\n",
    "\n",
    "    # Host identity verified (Pie)\n",
    "    with c3:\n",
    "        st.subheader(\"Host Identity Verified\")\n",
    "        if 'host_identity_verified' in dff.columns:\n",
    "            tabla = dff['host_identity_verified'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                                .rename(columns={'index': 'host_identity_verified'})\n",
    "            fig = px.pie(\n",
    "                tabla,\n",
    "                names='host_identity_verified', values='count',\n",
    "                title='Host Identity Verified',\n",
    "                hole=0.25,\n",
    "                color_discrete_sequence=palette[:2]\n",
    "            )\n",
    "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            show(fig)\n",
    "        else:\n",
    "            st.warning(\"No existe la columna 'host_identity_verified'.\")\n",
    "\n",
    "    # Has availability (Pie)\n",
    "    with c4:\n",
    "        st.subheader(\"Has Availability\")\n",
    "        if 'has_availability' in dff.columns:\n",
    "            tabla = dff['has_availability'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                        .rename(columns={'index': 'has_availability'})\n",
    "            fig = px.pie(\n",
    "                tabla,\n",
    "                names='has_availability', values='count',\n",
    "                title='Host Has Availability',\n",
    "                hole=0.25,\n",
    "                color_discrete_sequence=palette[:2]\n",
    "            )\n",
    "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            show(fig)\n",
    "        else:\n",
    "            st.warning(\"No existe la columna 'has_availability'.\")\n",
    "\n",
    "    # ====== Fila 3 ======\n",
    "    c5, c6 = st.columns(2)\n",
    "\n",
    "    # Host location (Barra)\n",
    "    with c5:\n",
    "        st.subheader(\"Host Location\")\n",
    "        if 'host_location' in dff.columns:\n",
    "            dff_loc = dff.copy()\n",
    "            pat_cdmx = r'(ciudad\\s+de\\s+m[ée]xico|cdmx|mexico\\s+city|m[ée]xico\\s*,?\\s*d\\.?\\s*f\\.?)'\n",
    "            mask = dff_loc['host_location'].astype(str).str.contains(pat_cdmx, case=False, na=False, regex=True)\n",
    "            dff_loc.loc[mask, 'host_location'] = 'CDMX'\n",
    "            dff_loc['host_location'] = dff_loc['host_location'].fillna('Unknown')\n",
    "            dff_loc['host_location'] = dff_loc['host_location'].replace(r'^\\s*(nan|none|unknown)?\\s*$', 'Unknown', regex=True)\n",
    "\n",
    "            tabla = dff_loc['host_location'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                            .rename(columns={'index': 'host_location'})\n",
    "            filtro = tabla[tabla['count'] > 200]\n",
    "            fig = px.bar(\n",
    "                filtro.sort_values('count', ascending=False),\n",
    "                x='host_location', y='count',\n",
    "                title='Host Location',\n",
    "                text='count',\n",
    "                color_discrete_sequence=palette\n",
    "            )\n",
    "            fig.update_layout(xaxis_title=None, yaxis_title='Frecuencia')\n",
    "            fig.update_xaxes(tickangle=45)\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"No existe la columna 'host_location'.\")\n",
    "\n",
    "    # Host acceptance rate (Pie con bins)\n",
    "    with c6:\n",
    "        st.subheader(\"Host Acceptance Rate\")\n",
    "        col = 'host_acceptance_rate'\n",
    "        if col in dff.columns and dff[col].notna().sum() > 0:\n",
    "            min1 = float(np.nanmin(dff[col]))\n",
    "            max1 = float(np.nanmax(dff[col]))\n",
    "            # 5 categorías tipo Likert; si min==max, mostramos una sola\n",
    "            if min1 == max1:\n",
    "                tabla = pd.DataFrame({'_har_cat': [f'{min1:.1f}'], 'count': [dff[col].notna().sum()]})\n",
    "            else:\n",
    "                bins = np.linspace(min1, max1, 6)\n",
    "                labels = ['Malo', 'Regular', 'Bueno', 'Muy Bueno', 'Excelente']\n",
    "                dff['_har_cat'] = pd.cut(dff[col], bins=bins, labels=labels, include_lowest=True)\n",
    "                tabla = dff['_har_cat'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                    .rename(columns={'index': '_har_cat'})\n",
    "\n",
    "            fig = px.pie(\n",
    "                tabla,\n",
    "                names='_har_cat',   # ← ahora SIEMPRE existe\n",
    "                values='count',\n",
    "                title='Host Acceptance Rate',\n",
    "                hole=0.25,\n",
    "                color_discrete_sequence=palette\n",
    "            )\n",
    "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"No hay datos numéricos en 'host_acceptance_rate'.\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# OPCIÓN 2: PROPERTY TYPE\n",
    "# ======================\n",
    "elif Variable_Cat == \"Property type\":\n",
    "    st.subheader(\"Características de la Propiedad\")\n",
    "\n",
    "    # ===== Fila 1: Property type & Room type =====\n",
    "    c1, c2 = st.columns(2)\n",
    "\n",
    "    with c1:\n",
    "        st.write(\"**Tipo de Propiedad**\")\n",
    "        tabla = df['property_type'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                .rename(columns={'index': 'property_type'})\n",
    "        top5 = tabla.head(10)\n",
    "        fig = px.bar(\n",
    "            top5,\n",
    "            x='property_type', y='count',\n",
    "            title='Property Type',\n",
    "            text='count',\n",
    "            color_discrete_sequence=[palette[0]]\n",
    "        )\n",
    "        fig.update_traces(textposition='outside')\n",
    "        fig.update_layout(xaxis_title=None, yaxis_title='Frecuencia', xaxis_tickangle=45)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    with c2:\n",
    "        st.write(\"**Tipo de Habitación**\")\n",
    "        tabla = df['room_type'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                            .rename(columns={'index': 'room_type'})\n",
    "        fig = px.bar(\n",
    "            tabla,\n",
    "            x='room_type', y='count',\n",
    "            title='Room Type',\n",
    "            text='count',\n",
    "            color_discrete_sequence=[palette[1]]\n",
    "        )\n",
    "        fig.update_traces(textposition='outside')\n",
    "        fig.update_layout(xaxis_title=None, yaxis_title='Frecuencia')\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ===== Fila 2: Beds & Bathrooms =====\n",
    "    c3, c4 = st.columns(2)\n",
    "\n",
    "    with c3:\n",
    "        st.write(\"**Número de Camas (Beds)**\")\n",
    "        df['_beds_cat'] = pd.cut(\n",
    "            df['beds'],\n",
    "            bins=np.linspace(0, df['beds'].max() + 1, 5),\n",
    "            labels=['1 cama', '2 camas', '3 camas', '4+ camas'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "        tabla = df['_beds_cat'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                            .rename(columns={'index': '_beds_cat'})\n",
    "        fig = px.pie(\n",
    "            tabla,\n",
    "            names='_beds_cat',\n",
    "            values='count',\n",
    "            title='Distribución de Camas',\n",
    "            color_discrete_sequence=palette\n",
    "        )\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    with c4:\n",
    "        st.write(\"**Número de Baños (Bathrooms)**\")\n",
    "        df['_bath_cat'] = pd.cut(\n",
    "            df['bathrooms'],\n",
    "            bins=np.linspace(0, df['bathrooms'].max() + 1, 5),\n",
    "            labels=['1 baño', '2 baños', '3 baños', '4+ baños'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "        tabla = df['_bath_cat'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                            .rename(columns={'index': '_bath_cat'})\n",
    "        fig = px.pie(\n",
    "            tabla,\n",
    "            names='_bath_cat',\n",
    "            values='count',\n",
    "            title='Distribución de Baños',\n",
    "            color_discrete_sequence=palette\n",
    "        )\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ===== Fila 3: Accommodates (Barras) =====\n",
    "    st.write(\"**Capacidad de Alojamiento (Accommodates)**\")\n",
    "    tabla = df['accommodates'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                            .rename(columns={'index': 'accommodates'}) \\\n",
    "                            .sort_values(by='accommodates')\n",
    "    fig = px.bar(\n",
    "        tabla,\n",
    "        x='accommodates', y='count',\n",
    "        title='Número de Personas que Acepta',\n",
    "        text='count',\n",
    "        color_discrete_sequence=[palette[2]]\n",
    "    )\n",
    "    fig.update_traces(textposition='outside')\n",
    "    fig.update_layout(xaxis_title='Capacidad', yaxis_title='Frecuencia')\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "# ======================\n",
    "# OPCIÓN 3: OVERALL\n",
    "# ======================\n",
    "elif Variable_Cat == \"Overall\":\n",
    "    st.subheader(\"Resumen General\")\n",
    "\n",
    "    # -------- Fila 1: Neighbourhood | Instant Bookable --------\n",
    "    c1, c2 = st.columns(2)\n",
    "    with c1:\n",
    "        st.subheader(\"Neighbourhood Cleansed\")\n",
    "        if 'neighbourhood_cleansed' in dff.columns:\n",
    "            tabla = dff['neighbourhood_cleansed'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                                .rename(columns={'index': 'neighbourhood_cleansed'})\n",
    "            fig = px.bar(\n",
    "                tabla.sort_values('count', ascending=False),\n",
    "                x='neighbourhood_cleansed', y='count',\n",
    "                title='Neighbourhood Cleansed',\n",
    "                text='count',\n",
    "                color_discrete_sequence=palette\n",
    "            )\n",
    "            fig.update_layout(xaxis_title=None, yaxis_title='Frecuencia')\n",
    "            fig.update_xaxes(tickangle=45)\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"La columna 'neighbourhood_cleansed' no está en el dataset.\")\n",
    "\n",
    "    with c2:\n",
    "        st.subheader(\"Instant Bookable\")\n",
    "        if 'instant_bookable' in dff.columns:\n",
    "            tabla = dff['instant_bookable'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                            .rename(columns={'index': 'instant_bookable'})\n",
    "            fig = px.pie(\n",
    "                tabla,\n",
    "                names='instant_bookable', values='count',\n",
    "                title='Instant Bookable',\n",
    "                hole=0.25,\n",
    "                color_discrete_sequence=palette[:2]\n",
    "            )\n",
    "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"La columna 'instant_bookable' no está en el dataset.\")\n",
    "\n",
    "    # -------- Fila 2: Price Distribution | Availability 365 --------\n",
    "    c3, c4 = st.columns(2)\n",
    "\n",
    "    with c3:\n",
    "        st.subheader(\"Price Distribution\")\n",
    "        if '_price_num' in dff.columns and dff['_price_num'].notna().sum() > 0:\n",
    "            fig = px.histogram(\n",
    "                dff, x='_price_num',\n",
    "                title='Price Distribution',\n",
    "                nbins=50,\n",
    "                color_discrete_sequence=[palette[0]]\n",
    "            )\n",
    "            fig.update_layout(xaxis_title='Precio (moneda original)', yaxis_title='Frecuencia')\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"No hay datos numéricos en 'price' después de convertir.\")\n",
    "\n",
    "    with c4:\n",
    "        st.subheader(\"Availability 365\")\n",
    "        if 'availability_365' in dff.columns and dff['availability_365'].notna().sum() > 0:\n",
    "            dff['_av_cat'] = pd.cut(\n",
    "                dff['availability_365'],\n",
    "                bins=np.linspace(0, 365.1, 6),\n",
    "                labels=['1-73', '74-146', '147-219', '220-292', '293-365'],\n",
    "                include_lowest=True\n",
    "            )\n",
    "            tabla = dff['_av_cat'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                    .rename(columns={'index': '_av_cat'})\n",
    "            fig = px.bar(\n",
    "                tabla.sort_values('count', ascending=False),\n",
    "                x='_av_cat', y='count',\n",
    "                title='Availability 365 Distribution',\n",
    "                text='count',\n",
    "                color_discrete_sequence=palette\n",
    "            )\n",
    "            fig.update_layout(xaxis_title=None, yaxis_title='Frecuencia')\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"No hay datos numéricos en 'availability_365'.\")\n",
    "\n",
    "    # -------- Fila 3: Review Scores (centrado) --------\n",
    "    c5, _ = st.columns(2)\n",
    "\n",
    "    with c5:\n",
    "        st.subheader(\"Review Scores Value\")\n",
    "        if 'review_scores_value' in dff.columns and dff['review_scores_value'].notna().sum() > 0:\n",
    "            # Asegura _rev_cat en dff si no existe o quedó vacío\n",
    "            if '_rev_cat' not in dff.columns or dff['_rev_cat'].isna().all():\n",
    "                rmin = float(np.nanmin(dff['review_scores_value']))\n",
    "                rmax = float(np.nanmax(dff['review_scores_value']))\n",
    "                bins_r = np.linspace(max(3.8, rmin), min(5.1, max(rmax, 5.0)), 6)\n",
    "                labels_r = ['Malo (3.8–4.1)', 'Regular (4.1–4.3)', 'Bueno (4.4–4.6)', 'Muy Bueno (4.7–4.9)', 'Excelente (5)']\n",
    "                dff['_rev_cat'] = pd.cut(\n",
    "                    dff['review_scores_value'],\n",
    "                    bins=bins_r, labels=labels_r, include_lowest=True\n",
    "                )\n",
    "\n",
    "            tabla = dff['_rev_cat'].value_counts(dropna=False).reset_index(name='count') \\\n",
    "                                    .rename(columns={'index': '_rev_cat'})\n",
    "            fig = px.pie(\n",
    "                tabla,\n",
    "                names='_rev_cat', values='count',\n",
    "                title='Review Scores',\n",
    "                hole=0.25,\n",
    "                color_discrete_sequence=palette\n",
    "            )\n",
    "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"No hay datos numéricos en 'review_scores_value'.\")\n",
    "\n",
    "# =====================================================================\n",
    "# ====================== VISTA: REGRESIÓN LINEAL ======================\n",
    "# =====================================================================\n",
    "\n",
    "    st.subheader(\n",
    "        (f\"Regresión Lineal {reg_type}\")\n",
    "    )\n",
    "\n",
    "\n",
    "def render_regresion_lineal(dff):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    import streamlit as st\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "    # ---------- Paletas (fallback si no existen globales) ----------\n",
    "    global palette, palette2\n",
    "    if \"palette\" not in globals():\n",
    "        palette = [\"#4C78A8\", \"#F58518\", \"#54A24B\", \"#E45756\", \"#72B7B2\"]\n",
    "    if \"palette2\" not in globals():\n",
    "        palette2 = \"Viridis\"\n",
    "\n",
    "    # ---------- Helpers ----------\n",
    "    def get_numeric_cols(df_):\n",
    "        return [c for c in df_.columns if pd.api.types.is_numeric_dtype(df_[c])]\n",
    "\n",
    "    def default_target(df_):\n",
    "        if '_price_num' in df_.columns and df_['_price_num'].notna().sum() > 0:\n",
    "            return '_price_num'\n",
    "        nums = get_numeric_cols(df_)\n",
    "        return nums[0] if nums else None\n",
    "\n",
    "    def rmse(y_true, y_pred):\n",
    "        try:\n",
    "            return mean_squared_error(y_true, y_pred, squared=False)\n",
    "        except TypeError:\n",
    "            return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    def safe_onehot():\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", drop=None, sparse_output=False)\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", drop=None, sparse=False)\n",
    "\n",
    "    def compute_feature_importance(df, y_col, num_feats_all, cat_feats_all, standardize, log_target):\n",
    "        \"\"\"\n",
    "        Ajuste provisional para estimar importancias por coeficiente:\n",
    "        - Numéricas: |coeficiente|\n",
    "        - Categóricas: norma L2 del bloque OHE por variable original\n",
    "        Devuelve ranking combinado y rankings separados.\n",
    "        \"\"\"\n",
    "        data = df.dropna(subset=[y_col]).copy()\n",
    "        if data.empty:\n",
    "            return [], [], []\n",
    "\n",
    "        X_tmp = data[num_feats_all + cat_feats_all].copy()\n",
    "        y_tmp = data[y_col].copy()\n",
    "\n",
    "        if log_target:\n",
    "            y_tmp = y_tmp.where(y_tmp > 0).dropna()\n",
    "            X_tmp = X_tmp.loc[y_tmp.index]\n",
    "\n",
    "        transformers = []\n",
    "        if num_feats_all:\n",
    "            transformers.append((\"num\", StandardScaler() if standardize else \"passthrough\", num_feats_all))\n",
    "        if cat_feats_all:\n",
    "            transformers.append((\"cat\", safe_onehot(), cat_feats_all))\n",
    "\n",
    "        pre = ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
    "        pipe = Pipeline([(\"pre\", pre), (\"lr\", LinearRegression())])\n",
    "\n",
    "        try:\n",
    "            pipe.fit(X_tmp, y_tmp)\n",
    "        except Exception:\n",
    "            return [], [], []\n",
    "\n",
    "        # Obtiene nombres reales (num + OHE)\n",
    "        feat_names = []\n",
    "        if num_feats_all:\n",
    "            feat_names += num_feats_all\n",
    "        cat_names_expanded = []\n",
    "        if cat_feats_all:\n",
    "            ohe = pipe.named_steps[\"pre\"].named_transformers_.get(\"cat\", None)\n",
    "            if hasattr(ohe, \"get_feature_names_out\"):\n",
    "                cat_names_expanded = ohe.get_feature_names_out(cat_feats_all).tolist()\n",
    "            feat_names += cat_names_expanded\n",
    "\n",
    "        coefs = np.array(pipe.named_steps[\"lr\"].coef_).ravel()\n",
    "        feat_names = feat_names[:len(coefs)]\n",
    "\n",
    "        # Importancia por variable original\n",
    "        importancias = {}\n",
    "\n",
    "        # numéricas: |coef|\n",
    "        for f in num_feats_all:\n",
    "            if f in feat_names:\n",
    "                idx = feat_names.index(f)\n",
    "                importancias[f] = abs(coefs[idx])\n",
    "\n",
    "        # categóricas: agrupar columnas OHE del mismo prefijo\n",
    "        for c in cat_feats_all:\n",
    "            # columnas OHE comienzan con \"c_\" o \"c__\" según sklearn; mejor buscar por prefijo exacto \"c__\"\n",
    "            # pero get_feature_names_out devuelve \"<col>_<categoria>\"\n",
    "            block = [abs(coefs[i]) for i, n in enumerate(feat_names) if n.startswith(c + \"_\")]\n",
    "            if block:\n",
    "                # norma L2 (robusta a #niveles)\n",
    "                importancias[c] = float(np.linalg.norm(block))\n",
    "\n",
    "        # Rankings\n",
    "        if not importancias:\n",
    "            return [], [], []\n",
    "\n",
    "        ranked = sorted(importancias.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        ranked_all = [k for k, _ in ranked]\n",
    "        ranked_num = [k for k in ranked_all if k in num_feats_all]\n",
    "        ranked_cat = [k for k in ranked_all if k in cat_feats_all]\n",
    "        return ranked_all, ranked_num, ranked_cat\n",
    "\n",
    "    # ========================= Sidebar (TODOS LOS CONTROLES) =========================\n",
    "    st.sidebar.header(\"Configuración del modelo\")\n",
    "\n",
    "    # Tipo de regresión (lista desplegable)\n",
    "    reg_type = st.sidebar.selectbox(\"Tipo de regresión\", [\"Múltiple\", \"Simple\"], index=0)\n",
    "\n",
    "    # Variables disponibles\n",
    "    numeric_cols = get_numeric_cols(dff)\n",
    "    if '_price_num' in dff.columns and '_price_num' not in numeric_cols:\n",
    "        numeric_cols = ['_price_num'] + numeric_cols\n",
    "    target_default = default_target(dff) or (numeric_cols[0] if numeric_cols else None)\n",
    "\n",
    "    y_col = st.sidebar.selectbox(\n",
    "        \"Variable dependiente (y)\",\n",
    "        options=numeric_cols,\n",
    "        index=(numeric_cols.index(target_default) if target_default in numeric_cols else 0)\n",
    "    )\n",
    "\n",
    "    # Candidatas\n",
    "    all_num_X = [c for c in numeric_cols if c != y_col]\n",
    "    cat_candidates = [c for c in ['property_type', 'room_type', 'neighbourhood_cleansed',\n",
    "                                  'instant_bookable', 'host_is_superhost'] if c in dff.columns]\n",
    "\n",
    "    # Hiper-parámetros comunes\n",
    "    test_size = st.sidebar.slider(\"Proporción de test\", 0.1, 0.4, 0.2, 0.05)\n",
    "    standardize = st.sidebar.checkbox(\"Estandarizar numéricas\", True)\n",
    "    log_target = st.sidebar.checkbox(\"Usar log(y)\", False)\n",
    "\n",
    "    # Controles específicos según tipo\n",
    "    if reg_type == \"Simple\":\n",
    "        # Solo X numérica\n",
    "        # Sugerir la más correlacionada con y\n",
    "        if all_num_X:\n",
    "            tmp = dff[[y_col] + all_num_X].copy()\n",
    "            for c in tmp.columns:\n",
    "                tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\")\n",
    "            tmp = tmp.dropna(subset=[y_col])\n",
    "            if tmp.shape[0] >= 5:\n",
    "                corrs = tmp.corr(numeric_only=True).get(y_col, pd.Series(dtype=float)).drop(labels=[y_col], errors=\"ignore\")\n",
    "                best = corrs.abs().sort_values(ascending=False).index.tolist()[:1]\n",
    "            else:\n",
    "                best = all_num_X[:1]\n",
    "        else:\n",
    "            best = []\n",
    "\n",
    "        x_simple = st.sidebar.selectbox(\n",
    "            \"Variable X (simple, solo numérica)\",\n",
    "            options=all_num_X,\n",
    "            index=(all_num_X.index(best[0]) if best else 0) if all_num_X else 0\n",
    "        )\n",
    "        num_feats = [x_simple] if all_num_X else []\n",
    "        cat_feats = []\n",
    "\n",
    "    else:\n",
    "        # Múltiple: preselección por mayor coeficiente (ajuste provisional)\n",
    "        ranked_all, ranked_num, ranked_cat = compute_feature_importance(\n",
    "            dff, y_col, all_num_X, cat_candidates, standardize, log_target\n",
    "        )\n",
    "        # Fallback si no se pudo estimar: usa top por correlación numérica\n",
    "        if not ranked_all:\n",
    "            tmp = dff[[y_col] + all_num_X].copy()\n",
    "            for c in tmp.columns:\n",
    "                tmp[c] = pd.to_numeric(tmp[c], errors=\"coerce\")\n",
    "            tmp = tmp.dropna(subset=[y_col])\n",
    "            if tmp.shape[0] >= 5 and all_num_X:\n",
    "                corrs = tmp.corr(numeric_only=True).get(y_col, pd.Series(dtype=float)).drop(labels=[y_col], errors=\"ignore\")\n",
    "                ranked_num = corrs.abs().sort_values(ascending=False).index.tolist()\n",
    "            else:\n",
    "                ranked_num = all_num_X\n",
    "            ranked_cat = cat_candidates\n",
    "\n",
    "        top_k_num = min(5, len(ranked_num))\n",
    "        top_k_cat = min(2, len(ranked_cat))  # pocas categóricas por defecto para evitar sobre-OHE\n",
    "        default_num_multi = ranked_num[:top_k_num]\n",
    "        default_cat_multi = ranked_cat[:top_k_cat]\n",
    "\n",
    "        manual_select = st.sidebar.checkbox(\"Seleccionar variables manualmente\", value=False)\n",
    "\n",
    "        if manual_select:\n",
    "            num_feats = st.sidebar.multiselect(\n",
    "                \"Variables numéricas (X)\",\n",
    "                options=all_num_X,\n",
    "                default=default_num_multi\n",
    "            )\n",
    "            cat_feats = st.sidebar.multiselect(\n",
    "                \"Variables categóricas (X)\",\n",
    "                options=sorted(cat_candidates),\n",
    "                default=default_cat_multi\n",
    "            )\n",
    "        else:\n",
    "            num_feats = default_num_multi\n",
    "            cat_feats = default_cat_multi\n",
    "            st.sidebar.caption(\n",
    "                \"Variables seleccionadas automáticamente por mayor importancia de coeficientes.\"\n",
    "            )\n",
    "\n",
    "    # ========================= Título =========================\n",
    "    st.markdown(f\"<h1 style='text-align:center;'>Regresión Lineal {reg_type}</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "    # ========================= Preparación y modelo =========================\n",
    "    data = dff.dropna(subset=[y_col]).copy()\n",
    "    used_cols = list(dict.fromkeys((num_feats or []) + (cat_feats or [])))\n",
    "    if not used_cols:\n",
    "        st.warning(\"Selecciona al menos una variable independiente.\")\n",
    "        return\n",
    "\n",
    "    X = data[used_cols].copy()\n",
    "    y = data[y_col].copy()\n",
    "\n",
    "    if log_target:\n",
    "        y = y.where(y > 0).dropna()\n",
    "        X = X.loc[y.index]\n",
    "\n",
    "    transformers = []\n",
    "    if num_feats:\n",
    "        transformers.append((\"num\", StandardScaler() if standardize else \"passthrough\", num_feats))\n",
    "    if cat_feats:\n",
    "        transformers.append((\"cat\", safe_onehot(), cat_feats))\n",
    "\n",
    "    pre = ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"lr\", LinearRegression())])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    yhat_train = pipe.predict(X_train)\n",
    "    yhat_test  = pipe.predict(X_test)\n",
    "\n",
    "    inv_t = np.exp if log_target else (lambda v: v)\n",
    "    y_train_eval, y_test_eval = inv_t(y_train), inv_t(y_test)\n",
    "    yhat_train_eval, yhat_test_eval = inv_t(yhat_train), inv_t(yhat_test)\n",
    "\n",
    "    rmse_tr, rmse_te = rmse(y_train_eval, yhat_train_eval), rmse(y_test_eval, yhat_test_eval)\n",
    "    mae_tr, mae_te = mean_absolute_error(y_train_eval, yhat_train_eval), mean_absolute_error(y_test_eval, yhat_test_eval)\n",
    "    r2_tr, r2_te = r2_score(y_train, yhat_train), r2_score(y_test, yhat_test)\n",
    "\n",
    "    # ========================= 1) Métricas =========================\n",
    "    st.markdown(\"## 1) Métricas del modelo\")\n",
    "    met = pd.DataFrame({\n",
    "        \"Conjunto\": [\"Train\", \"Test\"],\n",
    "        \"RMSE (espacio original)\": [rmse_tr, rmse_te],\n",
    "        \"MAE (espacio original)\":  [mae_tr, mae_te],\n",
    "        \"R² (espacio del modelo)\": [r2_tr, r2_te],\n",
    "    })\n",
    "    st.dataframe(met, use_container_width=True)\n",
    "\n",
    "    # ========================= 2) Predicho vs Real =========================\n",
    "    st.markdown(\"## 2) Predicho vs Real (Test)\")\n",
    "    df_pred = pd.DataFrame({\"Real\": y_test_eval, \"Predicho\": yhat_test_eval})\n",
    "    fig_sc = px.scatter(\n",
    "        df_pred, x=\"Real\", y=\"Predicho\", trendline=\"ols\",\n",
    "        color_discrete_sequence=palette, opacity=0.7,\n",
    "        labels={\"Real\": \"Valor real\", \"Predicho\": \"Predicción\"}\n",
    "    )\n",
    "    fig_sc.add_trace(go.Scatter(\n",
    "        x=[df_pred[\"Real\"].min(), df_pred[\"Real\"].max()],\n",
    "        y=[df_pred[\"Real\"].min(), df_pred[\"Real\"].max()],\n",
    "        mode=\"lines\", name=\"y = x\", line=dict(dash=\"dash\")\n",
    "    ))\n",
    "    st.plotly_chart(fig_sc, use_container_width=True)\n",
    "\n",
    "    # ========================= 3) Histograma de errores =========================\n",
    "    st.markdown(\"## 3) Histograma de errores (Test)\")\n",
    "    errores = y_test_eval - yhat_test_eval\n",
    "    fig_err = px.histogram(x=errores, nbins=40, color_discrete_sequence=palette,\n",
    "                           title=\"Distribución de errores del modelo\")\n",
    "    fig_err.add_vline(x=0, line_dash=\"dash\")\n",
    "    st.plotly_chart(fig_err, use_container_width=True)\n",
    "\n",
    "    # ========================= 4) Residuos vs Predicción =========================\n",
    "    st.markdown(\"## 4) Residuos vs Predicción (Test)\")\n",
    "    df_res = pd.DataFrame({\"ŷ\": yhat_test_eval, \"Residuo\": errores})\n",
    "    fig_res = px.scatter(\n",
    "        df_res, x=\"ŷ\", y=\"Residuo\", opacity=0.7,\n",
    "        color_discrete_sequence=palette, labels={\"ŷ\": \"Predicción (ŷ)\"}\n",
    "    )\n",
    "    fig_res.add_hline(y=0, line_dash=\"dash\")\n",
    "    st.plotly_chart(fig_res, use_container_width=True)\n",
    "\n",
    "    # ========================= 5) Importancia de variables =========================\n",
    "    st.markdown(\"## 5) Importancia de variables (coeficientes)\")\n",
    "    # Nombres expandidos para OHE y mapeo a variable original\n",
    "    feat_display = []\n",
    "    if num_feats:\n",
    "        feat_display += num_feats\n",
    "    if cat_feats:\n",
    "        ohe = pipe.named_steps[\"pre\"].named_transformers_.get(\"cat\", None)\n",
    "        if hasattr(ohe, \"get_feature_names_out\"):\n",
    "            feat_display += ohe.get_feature_names_out(cat_feats).tolist()\n",
    "\n",
    "    coefs = np.array(pipe.named_steps[\"lr\"].coef_).ravel()\n",
    "    coefs_df = pd.DataFrame({\n",
    "        \"feature\": feat_display[:len(coefs)],\n",
    "        \"coef\": coefs[:len(feat_display)]\n",
    "    })\n",
    "    coefs_df = coefs_df.sort_values(\"coef\", key=lambda s: s.abs(), ascending=False)\n",
    "\n",
    "    fig_cf = px.bar(\n",
    "        coefs_df.head(25), x=\"coef\", y=\"feature\",\n",
    "        orientation=\"h\", color=\"coef\", color_continuous_scale=palette2,\n",
    "        title=\"Coeficientes más importantes (|coef|)\"\n",
    "    )\n",
    "    st.plotly_chart(fig_cf, use_container_width=True)\n",
    "\n",
    "if View == \"Regresión Lineal\":\n",
    "     render_regresion_lineal(dff)\n",
    "\n",
    "# =====================================================================\n",
    "# ==================== VISTA: REGRESIÓN NO LINEAL =====================\n",
    "# =====================================================================\n",
    "def render_regresion_no_lineal(dff):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    import streamlit as st\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from scipy.optimize import curve_fit  # para sigmoide\n",
    "    import warnings\n",
    "\n",
    "    # ---------- Paletas fallback ----------\n",
    "    global palette, palette2\n",
    "    if \"palette\" not in globals():\n",
    "        palette = [\"#4C78A8\", \"#F58518\", \"#54A24B\", \"#E45756\", \"#72B7B2\"]\n",
    "    if \"palette2\" not in globals():\n",
    "        palette2 = \"Viridis\"\n",
    "\n",
    "    # ---------- Helpers ----------\n",
    "    def rmse(y_true, y_pred):\n",
    "        try:\n",
    "            return mean_squared_error(y_true, y_pred, squared=False)\n",
    "        except TypeError:\n",
    "            return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    def metrics_safe(y_true, y_pred):\n",
    "        y_true = np.asarray(y_true, dtype=float)\n",
    "        y_pred = np.asarray(y_pred, dtype=float)\n",
    "        m = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        if m.sum() < 2:\n",
    "            return np.nan, np.nan, np.nan\n",
    "        return (\n",
    "            rmse(y_true[m], y_pred[m]),\n",
    "            mean_absolute_error(y_true[m], y_pred[m]),\n",
    "            r2_score(y_true[m], y_pred[m])\n",
    "        )\n",
    "\n",
    "    def drop_na_num(df_, cols):\n",
    "        df2 = df_[list(cols)].copy()\n",
    "        for c in cols:\n",
    "            df2[c] = pd.to_numeric(df2[c], errors='coerce')\n",
    "        df2 = df2.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        return df2\n",
    "\n",
    "    def get_numeric_cols(df_):\n",
    "        return [c for c in df_.columns if pd.api.types.is_numeric_dtype(df_[c])]\n",
    "\n",
    "    def default_target(df_):\n",
    "        if '_price_num' in df_.columns and df_['_price_num'].notna().sum() > 0:\n",
    "            return '_price_num'\n",
    "        nums = get_numeric_cols(df_)\n",
    "        return nums[0] if nums else None\n",
    "\n",
    "    def rank_by_coef(df, y_col, X_cols):\n",
    "        \"\"\"\n",
    "        Ajuste lineal con estandarización para obtener |coef| por variable y rankear.\n",
    "        Devuelve lista de variables ordenadas desc por importancia.\n",
    "        \"\"\"\n",
    "        dat = drop_na_num(df, [y_col] + X_cols)\n",
    "        if dat.empty:\n",
    "            return []\n",
    "        y = dat[y_col].to_numpy().astype(float)\n",
    "        X = dat[X_cols].to_numpy().astype(float)\n",
    "        pipe = make_pipeline(StandardScaler(with_mean=True, with_std=True), LinearRegression())\n",
    "        try:\n",
    "            pipe.fit(X, y)\n",
    "            coefs = np.abs(pipe.named_steps[\"linearregression\"].coef_).ravel()\n",
    "        except Exception:\n",
    "            # Fallback: usar |corr| con y\n",
    "            coefs = np.abs(np.corrcoef(np.c_[y.reshape(-1, 1), X], rowvar=False)[0, 1:])\n",
    "        order = np.argsort(coefs)[::-1]\n",
    "        return [X_cols[i] for i in order]\n",
    "\n",
    "    # ================= Sidebar =================\n",
    "    # ================= Sidebar =================\n",
    "    st.sidebar.header(\"Configuración – Regresión No Lineal\")\n",
    "\n",
    "    # Tipo de regresión (Simple o Múltiple)\n",
    "    reg_type = st.sidebar.selectbox(\"Tipo de regresión\", [\"Múltiple\", \"Simple\"], index=0)\n",
    "\n",
    "    # Variables disponibles\n",
    "    numeric_cols = [c for c in dff.columns if pd.api.types.is_numeric_dtype(dff[c])]\n",
    "    if '_price_num' in dff.columns and '_price_num' not in numeric_cols:\n",
    "        numeric_cols = ['_price_num'] + numeric_cols\n",
    "\n",
    "    if not numeric_cols:\n",
    "        st.warning(\"No hay columnas numéricas disponibles.\")\n",
    "        return\n",
    "\n",
    "    # Variable dependiente\n",
    "    y_default = '_price_num' if '_price_num' in numeric_cols else numeric_cols[0]\n",
    "    y_col = st.sidebar.selectbox(\n",
    "        \"Variable dependiente (y)\",\n",
    "        options=numeric_cols,\n",
    "        index=(numeric_cols.index(y_default) if y_default in numeric_cols else 0)\n",
    "    )\n",
    "\n",
    "    # Variables predictoras candidatas\n",
    "    num_X_all = [c for c in numeric_cols if c != y_col]\n",
    "\n",
    "    # Función para rankear por coeficientes absolutos\n",
    "    def rank_by_coef(df, y_col, X_cols):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        import numpy as np\n",
    "\n",
    "        df2 = df[[y_col] + X_cols].copy()\n",
    "        for c in X_cols:\n",
    "            df2[c] = pd.to_numeric(df2[c], errors=\"coerce\")\n",
    "        df2 = df2.dropna()\n",
    "        if df2.empty:\n",
    "            return []\n",
    "\n",
    "        X = df2[X_cols].to_numpy().astype(float)\n",
    "        y = df2[y_col].to_numpy().astype(float)\n",
    "        model = make_pipeline(StandardScaler(), LinearRegression())\n",
    "        model.fit(X, y)\n",
    "        coefs = np.abs(model.named_steps[\"linearregression\"].coef_).ravel()\n",
    "        order = np.argsort(coefs)[::-1]\n",
    "        return [X_cols[i] for i in order]\n",
    "\n",
    "    # Ranking automático por coeficientes\n",
    "    ranked = rank_by_coef(dff, y_col, num_X_all) if num_X_all else []\n",
    "\n",
    "    # --- Selección de variables según tipo ---\n",
    "    if reg_type == \"Simple\":\n",
    "        st.sidebar.subheader(\"Configuración – Regresión Simple\")\n",
    "\n",
    "        manual_select = st.sidebar.checkbox(\"Seleccionar variable manualmente\", value=False)\n",
    "\n",
    "        if manual_select:\n",
    "            x_col = st.sidebar.selectbox(\n",
    "                \"Variable independiente (x)\",\n",
    "                options=num_X_all,\n",
    "                index=0 if num_X_all else None\n",
    "            )\n",
    "            used_num_feats = [x_col]\n",
    "        else:\n",
    "            best_x = ranked[0] if ranked else (num_X_all[0] if num_X_all else None)\n",
    "            used_num_feats = [best_x] if best_x else []\n",
    "            st.sidebar.caption(f\"Variable seleccionada automáticamente: **{used_num_feats[0]}**\")\n",
    "\n",
    "    else:\n",
    "        st.sidebar.subheader(\"Configuración – Regresión Múltiple\")\n",
    "\n",
    "        manual_select = st.sidebar.checkbox(\"Seleccionar variables manualmente\", value=False)\n",
    "\n",
    "        if manual_select:\n",
    "            used_num_feats = st.sidebar.multiselect(\n",
    "                \"Variables independientes (X)\",\n",
    "                options=num_X_all,\n",
    "                default=ranked[:5] if ranked else num_X_all[:5]\n",
    "            )\n",
    "        else:\n",
    "            used_num_feats = ranked[:5] if ranked else num_X_all[:5]\n",
    "            st.sidebar.caption(\"Variables seleccionadas automáticamente por mayor importancia de coeficientes.\")\n",
    "\n",
    "\n",
    "    # Título\n",
    "    st.markdown(f\"<h1 style='text-align:center;'>Regresión No Lineal {reg_type}</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "    # ================= Preparación de datos base =================\n",
    "    if reg_type == \"Simple\":\n",
    "        if not used_num_feats:\n",
    "            st.warning(\"No hay variable X seleccionada.\")\n",
    "            return\n",
    "        base = drop_na_num(dff, [used_num_feats[0], y_col])\n",
    "        if base.empty:\n",
    "            st.warning(\"No hay datos válidos para las columnas seleccionadas.\")\n",
    "            return\n",
    "        x = base[[used_num_feats[0]]].to_numpy().astype(float)\n",
    "        y = base[y_col].to_numpy().astype(float)\n",
    "    else:\n",
    "        if not used_num_feats:\n",
    "            st.warning(\"No hay variables predictoras seleccionadas automáticamente.\")\n",
    "            return\n",
    "        base = drop_na_num(dff, used_num_feats + [y_col])\n",
    "        if base.empty:\n",
    "            st.warning(\"No hay datos válidos para las columnas seleccionadas.\")\n",
    "            return\n",
    "        x = base[used_num_feats].to_numpy().astype(float)   # multivariado\n",
    "        y = base[y_col].to_numpy().astype(float)\n",
    "\n",
    "    # =============== Modelos (automático, sin sliders) ===============\n",
    "    # Para Polinomial elegimos automáticamente el mejor grado en 1..6 por RMSE.\n",
    "    DEG_MIN, DEG_MAX = 1,6\n",
    "\n",
    "    results = []\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    # ---- Lineal (siempre) ----\n",
    "    lin = LinearRegression().fit(x, y)\n",
    "    yhat_lin = lin.predict(x)\n",
    "    results.append({\n",
    "        \"name\": \"Lineal\",\n",
    "        \"yhat\": yhat_lin,\n",
    "        \"rmse\": rmse(y, yhat_lin),\n",
    "        \"mae\": mean_absolute_error(y, yhat_lin),\n",
    "        \"r2\": r2_score(y, yhat_lin)\n",
    "    })\n",
    "\n",
    "    # ---- Polinomial (mejor grado 1..6) ----\n",
    "    best_deg = 1\n",
    "    best_rmse = np.inf\n",
    "    for d in range(1, DEG_MAX + 1):\n",
    "        poly = PolynomialFeatures(degree=d, include_bias=False)\n",
    "        Xp = poly.fit_transform(x)\n",
    "        mdl = LinearRegression().fit(Xp, y)\n",
    "        yhat_d = mdl.predict(Xp)\n",
    "        rmse_d = rmse(y, yhat_d)\n",
    "        if np.isfinite(rmse_d) and rmse_d < best_rmse:\n",
    "            best_rmse = rmse_d\n",
    "            best_deg = d\n",
    "            best_poly = poly\n",
    "            best_poly_mdl = mdl\n",
    "            best_poly_yhat = yhat_d\n",
    "\n",
    "    results.append({\n",
    "        \"name\": f\"Polinomial (g={best_deg})\",\n",
    "        \"yhat\": best_poly_yhat,\n",
    "        \"rmse\": best_rmse,\n",
    "        \"mae\": mean_absolute_error(y, best_poly_yhat),\n",
    "        \"r2\": r2_score(y, best_poly_yhat)\n",
    "    })\n",
    "\n",
    "    # ---- Exponencial / Logarítmico / Sigmoide solo si Simple ----\n",
    "    res_exp = res_log = res_sig = None\n",
    "    if reg_type == \"Simple\":\n",
    "        xv = x.ravel()\n",
    "\n",
    "        # Exponencial: y = A * exp(bx)  <=> ln(y) = ln(A) + b x\n",
    "        mask_ypos = y > 0\n",
    "        if mask_ypos.sum() >= 5:\n",
    "            y_pos = y[mask_ypos]\n",
    "            x_pos = xv[mask_ypos]\n",
    "            ln_y = np.log(y_pos)\n",
    "            lin_exp = LinearRegression().fit(x_pos.reshape(-1, 1), ln_y)\n",
    "            yhat_exp_full = np.exp(lin_exp.intercept_ + lin_exp.coef_[0] * xv)\n",
    "            r_rmse, r_mae, r_r2 = metrics_safe(y, yhat_exp_full)\n",
    "            res_exp = {\"name\": \"Exponencial\", \"yhat\": yhat_exp_full, \"rmse\": r_rmse, \"mae\": r_mae, \"r2\": r_r2}\n",
    "            results.append(res_exp)\n",
    "\n",
    "        # Logarítmico: y = a + b ln(x)\n",
    "        mask_xpos = xv > 0\n",
    "        if mask_xpos.sum() >= 5:\n",
    "            x_pos = xv[mask_xpos]\n",
    "            y_pos2 = y[mask_xpos]\n",
    "            ln_x = np.log(x_pos.reshape(-1, 1))\n",
    "            lin_log = LinearRegression().fit(ln_x, y_pos2)\n",
    "            yhat_log_full = np.full_like(y, np.nan, dtype=float)\n",
    "            yhat_log_full[mask_xpos] = lin_log.predict(np.log(xv[mask_xpos].reshape(-1, 1))).ravel()\n",
    "            r_rmse, r_mae, r_r2 = metrics_safe(y, yhat_log_full)\n",
    "            res_log = {\"name\": \"Logarítmico\", \"yhat\": yhat_log_full, \"rmse\": r_rmse, \"mae\": r_mae, \"r2\": r_r2}\n",
    "            results.append(res_log)\n",
    "\n",
    "        # Sigmoide: y = L / (1 + exp(-k(x-x0)))\n",
    "        try:\n",
    "            def sigmoid(xv, L, k, x0): return L / (1.0 + np.exp(-k * (xv - x0)))\n",
    "            L0 = np.nanmax(y) if np.isfinite(np.nanmax(y)) else 1.0\n",
    "            k0 = 1.0 / (np.nanstd(xv) + 1e-8)\n",
    "            x00 = np.nanmedian(xv)\n",
    "            popt, _ = curve_fit(sigmoid, xv, y, p0=[L0, k0, x00], maxfev=20000)\n",
    "            yhat_sig = sigmoid(xv, *popt)\n",
    "            r_rmse, r_mae, r_r2 = metrics_safe(y, yhat_sig)\n",
    "            res_sig = {\"name\": \"Sigmoide\", \"yhat\": yhat_sig, \"rmse\": r_rmse, \"mae\": r_mae, \"r2\": r_r2}\n",
    "            results.append(res_sig)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ================= Comparativa de modelos =================\n",
    "    comp = pd.DataFrame([{\"Modelo\": r[\"name\"], \"RMSE\": r[\"rmse\"], \"MAE\": r[\"mae\"], \"R²\": r[\"r2\"]} for r in results])\n",
    "    comp[\"rank_rmse\"] = comp[\"RMSE\"].rank(method=\"min\")\n",
    "    comp[\"rank_r2\"] = (-comp[\"R²\"]).rank(method=\"min\")\n",
    "    comp[\"score_mix\"] = comp[\"rank_rmse\"] + comp[\"rank_r2\"]\n",
    "    comp = comp.sort_values([\"rank_rmse\", \"rank_r2\"]).reset_index(drop=True)\n",
    "\n",
    "    best_name = comp.loc[0, \"Modelo\"]\n",
    "    st.markdown(\"### Comparativa de modelos\")\n",
    "    st.dataframe(comp[[\"Modelo\", \"RMSE\", \"MAE\", \"R²\"]], use_container_width=True)\n",
    "    st.success(f\"Mejor modelo (criterio mixto RMSE & R²): {best_name}\")\n",
    "\n",
    "    # ================= Gráficos =================\n",
    "    if reg_type == \"Simple\":\n",
    "        # Dispersión + curvas estimadas\n",
    "        st.markdown(\"### Ajuste de todos los modelos\")\n",
    "        xv = x.ravel()\n",
    "        x_grid = np.linspace(np.nanmin(xv), np.nanmax(xv), 200).reshape(-1, 1)\n",
    "\n",
    "        def predict_on_grid(model_name):\n",
    "            if model_name == \"Lineal\":\n",
    "                return LinearRegression().fit(x, y).predict(x_grid).ravel()\n",
    "            elif model_name.startswith(\"Polinomial\"):\n",
    "                poly_g = PolynomialFeatures(degree=best_deg, include_bias=False)\n",
    "                Xg = poly_g.fit_transform(x_grid)\n",
    "                return LinearRegression().fit(best_poly.fit_transform(x), y).predict(Xg).ravel()\n",
    "            elif model_name == \"Exponencial\" and res_exp is not None:\n",
    "                # re-entrena en ln(y) con y>0\n",
    "                mask_ypos = y > 0\n",
    "                ln_y = np.log(y[mask_ypos])\n",
    "                lin_exp = LinearRegression().fit(x[mask_ypos], ln_y)\n",
    "                return np.exp(lin_exp.intercept_ + lin_exp.coef_[0] * x_grid.ravel())\n",
    "            elif model_name == \"Logarítmico\" and res_log is not None:\n",
    "                out = np.full_like(x_grid.ravel(), np.nan, dtype=float)\n",
    "                maskg = x_grid.ravel() > 0\n",
    "                lin_log = LinearRegression().fit(np.log(x[ (x.ravel()>0) ]), y[(x.ravel()>0)])\n",
    "                out[maskg] = lin_log.predict(np.log(x_grid[maskg])).ravel()\n",
    "                return out\n",
    "            elif model_name == \"Sigmoide\" and res_sig is not None:\n",
    "                def sigmoid(xv, L, k, x0): return L / (1.0 + np.exp(-k * (xv - x0)))\n",
    "                try:\n",
    "                    L0 = np.nanmax(y); k0 = 1.0/(np.nanstd(xv)+1e-8); x00 = np.nanmedian(xv)\n",
    "                    popt, _ = curve_fit(sigmoid, xv, y, p0=[L0, k0, x00], maxfev=20000)\n",
    "                    return sigmoid(x_grid.ravel(), *popt)\n",
    "                except Exception:\n",
    "                    return np.full_like(x_grid.ravel(), np.nan)\n",
    "            return np.full_like(x_grid.ravel(), np.nan)\n",
    "\n",
    "        fig_all = px.scatter(base, x=used_num_feats[0], y=y_col, opacity=0.5,\n",
    "                             title=\"Ajustes no lineales\", color_discrete_sequence=palette)\n",
    "        for r in results:\n",
    "            y_grid = predict_on_grid(r[\"name\"])\n",
    "            fig_all.add_trace(go.Scatter(x=x_grid.ravel(), y=y_grid, mode=\"lines\",\n",
    "                                         name=r[\"name\"], line=dict(width=2)))\n",
    "        st.plotly_chart(fig_all, use_container_width=True)\n",
    "    else:\n",
    "        # En múltiple, mostramos Predicho vs Real para los dos modelos aplicables (Lineal y Polinomial)\n",
    "        st.markdown(\"### Predicho vs Real (múltiple)\")\n",
    "        df_pred = pd.DataFrame({\"Real\": y, \"Lineal\": yhat_lin, f\"Polinomial(g={best_deg})\": results[1][\"yhat\"]})\n",
    "        # Scatter Lineal\n",
    "        fig_sc1 = px.scatter(df_pred, x=\"Real\", y=\"Lineal\", trendline=\"ols\",\n",
    "                             title=\"Predicho vs Real – Lineal\", color_discrete_sequence=palette, opacity=0.7)\n",
    "        fig_sc1.add_trace(go.Scatter(x=[df_pred[\"Real\"].min(), df_pred[\"Real\"].max()],\n",
    "                                     y=[df_pred[\"Real\"].min(), df_pred[\"Real\"].max()],\n",
    "                                     mode=\"lines\", name=\"y=x\", line=dict(dash=\"dash\")))\n",
    "        st.plotly_chart(fig_sc1, use_container_width=True)\n",
    "        # Scatter Polinomial\n",
    "        fig_sc2 = px.scatter(df_pred, x=\"Real\", y=f\"Polinomial(g={best_deg})\", trendline=\"ols\",\n",
    "                             title=f\"Predicho vs Real – Polinomial (g={best_deg})\",\n",
    "                             color_discrete_sequence=palette, opacity=0.7)\n",
    "        fig_sc2.add_trace(go.Scatter(x=[df_pred[\"Real\"].min(), df_pred[\"Real\"].max()],\n",
    "                                     y=[df_pred[\"Real\"].min(), df_pred[\"Real\"].max()],\n",
    "                                     mode=\"lines\", name=\"y=x\", line=dict(dash=\"dash\")))\n",
    "        st.plotly_chart(fig_sc2, use_container_width=True)\n",
    "\n",
    "    # ================= Curva RMSE vs Grado (1..6 fijo) =================\n",
    "    st.markdown(\"### Error (RMSE) vs grado polinomial\")\n",
    "    degs = list(range(1, DEG_MAX + 1))\n",
    "    rmses = []\n",
    "    for d in degs:\n",
    "        poly_d = PolynomialFeatures(degree=d, include_bias=False)\n",
    "        Xd = poly_d.fit_transform(x)\n",
    "        mdl = LinearRegression().fit(Xd, y)\n",
    "        yhat_d = mdl.predict(Xd)\n",
    "        rmses.append(rmse(y, yhat_d))\n",
    "    fig_deg = px.line(x=degs, y=rmses, markers=True,\n",
    "                      labels={\"x\": \"Grado\", \"y\": \"RMSE\"},\n",
    "                      title=\"RMSE vs Grado (Polinomial)\",\n",
    "                      color_discrete_sequence=palette)\n",
    "    st.plotly_chart(fig_deg, use_container_width=True)\n",
    "\n",
    "    # ================= Residuos del mejor modelo =================\n",
    "    yhat_best = [r for r in results if r[\"name\"] == best_name][0][\"yhat\"]\n",
    "    resid = y - yhat_best\n",
    "\n",
    "    st.markdown(\"### Histograma de residuos (mejor modelo)\")\n",
    "    fig_hist = px.histogram(x=resid, nbins=50, labels={\"x\": \"Residuo\"},\n",
    "                            title=f\"Distribución de residuos – {best_name}\")\n",
    "    fig_hist.add_vline(x=0, line_dash=\"dash\")\n",
    "    st.plotly_chart(fig_hist, use_container_width=True)\n",
    "\n",
    "    st.markdown(\"### Mapa de calor de residuos (ŷ vs residuo)\")\n",
    "    fig_dh = px.density_heatmap(x=yhat_best, y=resid,\n",
    "                                labels={\"x\": \"ŷ (predicho)\", \"y\": \"Residuo\"},\n",
    "                                title=f\"Residuo vs ŷ – {best_name}\",\n",
    "                                nbinsx=40, nbinsy=40, color_continuous_scale=palette2)\n",
    "    st.plotly_chart(fig_dh, use_container_width=True)\n",
    "\n",
    "\n",
    "# Mostrar vista no lineal\n",
    "if View == \"Regresión No Lineal\":\n",
    "    render_regresion_no_lineal(dff)\n",
    "\n",
    "# =====================================================================\n",
    "# ===================== VISTA: REGRESIÓN LOGÍSTICA ====================\n",
    "# =====================================================================\n",
    "def render_regresion_logistica(dff):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import streamlit as st\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import (\n",
    "        confusion_matrix, roc_curve, auc,\n",
    "        precision_recall_curve, average_precision_score,\n",
    "        precision_score, recall_score, f1_score, accuracy_score\n",
    "    )\n",
    "\n",
    "    st.subheader(\"Regresión Logística\")\n",
    "\n",
    "    # ---------------- Helpers ----------------\n",
    "    def is_binary_series(s: pd.Series) -> bool:\n",
    "        \"\"\"Detecta columnas binarias (incluye True/False, 0/1, 't'/'f'/'true'/'false').\"\"\"\n",
    "        vals = pd.unique(s.dropna())\n",
    "        if len(vals) == 0:\n",
    "            return False\n",
    "        # numéricas 0/1\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            u = pd.unique(pd.to_numeric(s, errors=\"coerce\").dropna())\n",
    "            return set(np.unique(u)).issubset({0, 1})\n",
    "        # booleanas\n",
    "        if pd.api.types.is_bool_dtype(s):\n",
    "            return True\n",
    "        # strings tipo true/false\n",
    "        vs = pd.Series(vals).astype(str).str.lower().str.strip()\n",
    "        bin_like = {\"0\",\"1\",\"true\",\"false\",\"t\",\"f\",\"yes\",\"no\",\"y\",\"n\"}\n",
    "        return vs.isin(list(bin_like)).all()\n",
    "\n",
    "    def to_binary(s: pd.Series) -> pd.Series:\n",
    "        \"\"\"Convierte una serie binaria a {0,1} de forma robusta.\"\"\"\n",
    "        if pd.api.types.is_bool_dtype(s):\n",
    "            return s.astype(int)\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            return (pd.to_numeric(s, errors=\"coerce\") > 0).astype(int)\n",
    "        # string mapping\n",
    "        m = {\"true\":1,\"t\":1,\"yes\":1,\"y\":1,\"1\":1,\n",
    "             \"false\":0,\"f\":0,\"no\":0,\"n\":0,\"0\":0}\n",
    "        return s.astype(str).str.lower().str.strip().map(m).astype(\"Int64\").astype(int)\n",
    "\n",
    "    def safe_metrics(y_true, y_prob, thr):\n",
    "        \"\"\"Métricas con umbral; ignora pares no finitos.\"\"\"\n",
    "        y_true = np.asarray(y_true, dtype=float)\n",
    "        y_prob = np.asarray(y_prob, dtype=float)\n",
    "        m = np.isfinite(y_true) & np.isfinite(y_prob)\n",
    "        if m.sum() == 0:\n",
    "            return dict(acc=np.nan, prec=np.nan, rec=np.nan, f1=np.nan)\n",
    "        y_pred = (y_prob[m] >= thr).astype(int)\n",
    "        return dict(\n",
    "            acc = accuracy_score(y_true[m], y_pred),\n",
    "            prec= precision_score(y_true[m], y_pred, zero_division=0),\n",
    "            rec = recall_score(y_true[m], y_pred, zero_division=0),\n",
    "            f1  = f1_score(y_true[m], y_pred, zero_division=0)\n",
    "        )\n",
    "\n",
    "    # ---------------- Sidebar: Controles ----------------\n",
    "    st.sidebar.markdown(\"### Controles — Logística\")\n",
    "\n",
    "    # Sugerir targets binarios disponibles\n",
    "    candidate_targets = [c for c in dff.columns if is_binary_series(dff[c])]\n",
    "    if not candidate_targets:\n",
    "        st.warning(\"No encuentro columnas binarias en tus datos. Crea una y vuelve a esta vista (p. ej. has_availability, host_is_superhost, etc.).\")\n",
    "        return\n",
    "\n",
    "    target_col = st.sidebar.selectbox(\"Variable objetivo (binaria)\", candidate_targets, key=\"lg_target\")\n",
    "\n",
    "    # Features: numéricas y categóricas\n",
    "    num_cols = [c for c in dff.columns if pd.api.types.is_numeric_dtype(dff[c]) and c != target_col]\n",
    "    cat_cols = [c for c in dff.columns if (not pd.api.types.is_numeric_dtype(dff[c])) and c != target_col]\n",
    "\n",
    "    sel_num = st.sidebar.multiselect(\"Variables numéricas (X)\", num_cols, default=num_cols[:5], key=\"lg_num\")\n",
    "    sel_cat = st.sidebar.multiselect(\"Variables categóricas (X)\", cat_cols, default=[c for c in cat_cols if c in [\"room_type\",\"property_type\",\"neighbourhood_cleansed\"]], key=\"lg_cat\")\n",
    "\n",
    "    test_size = st.sidebar.slider(\"Test size\", 0.1, 0.4, 0.2, 0.05, key=\"lg_test\")\n",
    "    standardize = st.sidebar.checkbox(\"Estandarizar numéricas\", value=True, key=\"lg_std\")\n",
    "    balanced = st.sidebar.checkbox(\"Balancear clases (class_weight='balanced')\", value=True, key=\"lg_bal\")\n",
    "    C_val = st.sidebar.number_input(\"Regularización (C, mayor = menos regularización)\", min_value=0.001, value=1.0, step=0.5, key=\"lg_C\")\n",
    "    thr = st.sidebar.slider(\"Umbral de decisión\", 0.0, 1.0, 0.50, 0.01, key=\"lg_thr\")\n",
    "    normalize_cm = st.sidebar.checkbox(\"Normalizar matriz de confusión\", value=True, key=\"lg_cm_norm\")\n",
    "\n",
    "    used_cols = sel_num + sel_cat\n",
    "    if not used_cols:\n",
    "        st.info(\"Selecciona al menos una variable independiente (numérica o categórica).\")\n",
    "        return\n",
    "\n",
    "    # ---------------- Preparación de datos ----------------\n",
    "    df_local = dff.copy()\n",
    "\n",
    "    # y binaria robusta\n",
    "    y_raw = df_local[target_col]\n",
    "    if not is_binary_series(y_raw):\n",
    "        st.warning(\"La columna objetivo no parece binaria después de limpiar.\")\n",
    "        return\n",
    "    y_all = to_binary(y_raw)\n",
    "\n",
    "    # X\n",
    "    X_all = df_local[used_cols].copy()\n",
    "\n",
    "    # Quitamos filas con NA en X o y\n",
    "    data = pd.concat([X_all, y_all.rename(\"__y__\")], axis=1).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if data.empty:\n",
    "        st.warning(\"Sin datos válidos tras eliminar NaN/inf en X o y.\")\n",
    "        return\n",
    "\n",
    "    X = data[used_cols]\n",
    "    y = data[\"__y__\"].astype(int).to_numpy()\n",
    "\n",
    "    # Preprocesamiento\n",
    "    transformers = []\n",
    "    if sel_num:\n",
    "        transformers.append((\"num\", StandardScaler() if standardize else \"passthrough\", sel_num))\n",
    "    if sel_cat:\n",
    "        try:\n",
    "            ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError:\n",
    "            ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "        transformers.append((\"cat\", ohe, sel_cat))\n",
    "\n",
    "    pre = ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
    "\n",
    "    lr_args = dict(max_iter=1000, C=float(C_val), solver=\"lbfgs\")\n",
    "    if balanced:\n",
    "        lr_args[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"pre\", pre),\n",
    "        (\"clf\", LogisticRegression(**lr_args))\n",
    "    ])\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=float(test_size), random_state=42, stratify=y)\n",
    "\n",
    "    # Fit\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Probabilidades y predicción\n",
    "    y_proba_test = pipe.predict_proba(X_test)[:, 1]\n",
    "    y_pred_test  = (y_proba_test >= thr).astype(int)\n",
    "\n",
    "    # ---------------- Métricas con el umbral elegido ----------------\n",
    "    mets = safe_metrics(y_test, y_proba_test, thr)\n",
    "    st.markdown(\"### Métricas (Test) con umbral seleccionado\")\n",
    "    st.write(pd.DataFrame([{\n",
    "        \"Accuracy\": round(mets[\"acc\"], 4),\n",
    "        \"Precision\": round(mets[\"prec\"], 4),\n",
    "        \"Recall\": round(mets[\"rec\"], 4),\n",
    "        \"F1\": round(mets[\"f1\"], 4)\n",
    "    }]))\n",
    "\n",
    "    # ---------------- Matriz de Confusión ----------------\n",
    "    if normalize_cm:\n",
    "        cm = confusion_matrix(y_test, y_pred_test, normalize=\"true\")\n",
    "        cm_title = \"Matriz de Confusión (normalizada)\"\n",
    "        zmin, zmax, fmt = 0, 1, \".2f\"\n",
    "    else:\n",
    "        cm = confusion_matrix(y_test, y_pred_test)\n",
    "        cm_title = \"Matriz de Confusión\"\n",
    "        zmin, zmax, fmt = 0, cm.max(), \"d\"\n",
    "\n",
    "    fig_cm = px.imshow(\n",
    "        cm, text_auto=True, zmin=zmin, zmax=zmax, color_continuous_scale= palette2,\n",
    "        labels=dict(x=\"Predicho\", y=\"Real\", color=\"Valor\"), title=cm_title\n",
    "    )\n",
    "    fig_cm.update_xaxes(tickmode=\"array\", tickvals=[0,1], ticktext=[\"0\",\"1\"])\n",
    "    fig_cm.update_yaxes(tickmode=\"array\", tickvals=[0,1], ticktext=[\"0\",\"1\"])\n",
    "    st.plotly_chart(fig_cm, use_container_width=True)\n",
    "\n",
    "    # ---------------- Curva ROC y AUC ----------------\n",
    "    from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba_test)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig_roc = go.Figure()\n",
    "    fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode=\"lines\", name=f\"ROC (AUC={roc_auc:.3f})\"))\n",
    "    fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], mode=\"lines\", name=\"Azar\", line=dict(dash=\"dash\")))\n",
    "    fig_roc.update_layout(title=\"Curva ROC\", xaxis_title=\"FPR\", yaxis_title=\"TPR\")\n",
    "    show(fig_roc)\n",
    "\n",
    "    # ---------------- Curva Precision–Recall ----------------\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_proba_test)\n",
    "    ap = average_precision_score(y_test, y_proba_test)\n",
    "    fig_pr = go.Figure()\n",
    "    fig_pr.add_trace(go.Scatter(x=rec, y=prec, mode=\"lines\", name=f\"PR (AP={ap:.3f})\", line=dict(color=palette[1])))\n",
    "    fig_pr.update_layout(title=\"Curva Precision–Recall\", xaxis_title=\"Recall\", yaxis_title=\"Precision\", )\n",
    "    st.plotly_chart(fig_pr, use_container_width=True)\n",
    "\n",
    "    # ---------------- Distribución de probabilidades ----------------\n",
    "    fig_hist = px.histogram(x=y_proba_test, nbins=40, title=\"Distribución de probabilidades predichas (Test)\")\n",
    "    fig_hist.add_vline(x=thr, line_dash=\"dash\", line_color=\"black\")\n",
    "    fig_hist.update_xaxes(title=\"P(clase=1)\")\n",
    "    st.plotly_chart(fig_hist, use_container_width=True)\n",
    "\n",
    "    # ---------------- Curva de umbral (Precision/Recall/F1 vs threshold) ----------------\n",
    "    thresholds = np.linspace(0.0, 1.0, 101)\n",
    "    precs, recs, f1s = [], [], []\n",
    "    for t in thresholds:\n",
    "        m = safe_metrics(y_test, y_proba_test, t)\n",
    "        precs.append(m[\"prec\"]); recs.append(m[\"rec\"]); f1s.append(m[\"f1\"])\n",
    "    fig_thr = go.Figure()\n",
    "    fig_thr.add_trace(go.Scatter(x=thresholds, y=precs, mode=\"lines\", name=\"Precision\", line=dict(color=palette[0])))\n",
    "    fig_thr.add_trace(go.Scatter(x=thresholds, y=recs, mode=\"lines\", name=\"Recall\", line=dict(color=palette[1])))\n",
    "    fig_thr.add_trace(go.Scatter(x=thresholds, y=f1s, mode=\"lines\", name=\"F1\", line=dict(color=palette[2])))\n",
    "    fig_thr.add_vline(x=thr, line_dash=\"dash\", line_color=\"black\")\n",
    "    fig_thr.update_layout(title=\"Precision / Recall / F1 vs Umbral\", xaxis_title=\"Umbral\", yaxis_title=\"Score\")\n",
    "    st.plotly_chart(fig_thr, use_container_width=True)\n",
    "\n",
    "    # ---------------- Importancia de variables (coeficientes) ----------------\n",
    "    # Recuperar nombres de features tras el preprocesamiento\n",
    "    feat_names = []\n",
    "    if sel_num:\n",
    "        feat_names += sel_num\n",
    "    if sel_cat:\n",
    "        ohe = pipe.named_steps[\"pre\"].named_transformers_.get(\"cat\")\n",
    "        if hasattr(ohe, \"get_feature_names_out\"):\n",
    "            feat_names += ohe.get_feature_names_out(sel_cat).tolist()\n",
    "        else:\n",
    "            # compat versiones muy viejas\n",
    "            for c in sel_cat:\n",
    "                feat_names.append(c)\n",
    "\n",
    "    coefs = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "    coef_df = pd.DataFrame({\"feature\": feat_names[:len(coefs)], \"coef\": coefs})\n",
    "    coef_df = coef_df.sort_values(\"coef\", key=lambda s: s.abs(), ascending=False)\n",
    "\n",
    "    fig_coef = px.bar(coef_df.head(30), x=\"coef\", y=\"feature\", orientation=\"h\",\n",
    "                      title=\"Importancia de variables (coeficientes)\", color=\"coef\",\n",
    "                      color_continuous_scale= palette2)\n",
    "    st.plotly_chart(fig_coef, use_container_width=True)\n",
    "\n",
    "    # ---------------- Predicción vs Real (prob vs etiqueta) ----------------\n",
    "    fig_sc = px.strip(\n",
    "        x=y_test.astype(int), y=y_proba_test,\n",
    "        labels={\"x\": \"Real (0/1)\", \"y\": \"P(clase=1)\"},\n",
    "        title=\"Probabilidades predichas por clase real\",\n",
    "        color_discrete_sequence= [palette[1]]\n",
    "    )\n",
    "    fig_sc.add_hline(y=thr, line_dash=\"dash\")\n",
    "    st.plotly_chart(fig_sc, use_container_width=True)\n",
    "\n",
    "# Mostrar vista logística\n",
    "if View == \"Regresión Logística\":\n",
    "    render_regresion_logistica(dff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
